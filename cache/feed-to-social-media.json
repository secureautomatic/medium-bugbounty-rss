{"id":"https://medium.com/p/9354f26a8353","title":"Hacking AI — Understanding LLM Attacks and Prompt Injections","link":"https://medium.com/@anmol.sh/hacking-ai-understanding-llm-attacks-and-prompt-injections-9354f26a8353?source=rss------bug_bounty-5","published":1732913878000,"description":"The integration of Large Language Models (LLMs) into online platforms presents a double-edged sword, offering enhanced user experience but&#x2026;Continue reading on Medium »","category":["ai","hacking","penetration-testing","artificial-intelligence","bug-bounty"],"pubDate":"Fri, 29 Nov 2024 20:57:58 GMT"}